{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89fc05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d91c5ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>2023-05-09 00:00:00-03:00</th>\n",
       "      <th>2023-05-10 00:00:00-03:00</th>\n",
       "      <th>2023-05-11 00:00:00-03:00</th>\n",
       "      <th>2023-05-12 00:00:00-03:00</th>\n",
       "      <th>2023-05-15 00:00:00-03:00</th>\n",
       "      <th>2023-05-16 00:00:00-03:00</th>\n",
       "      <th>2023-05-17 00:00:00-03:00</th>\n",
       "      <th>2023-05-18 00:00:00-03:00</th>\n",
       "      <th>2023-05-19 00:00:00-03:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-05-25 00:00:00-03:00</th>\n",
       "      <th>2023-05-26 00:00:00-03:00</th>\n",
       "      <th>2023-05-29 00:00:00-03:00</th>\n",
       "      <th>2023-05-30 00:00:00-03:00</th>\n",
       "      <th>2023-05-31 00:00:00-03:00</th>\n",
       "      <th>2023-06-01 00:00:00-03:00</th>\n",
       "      <th>2023-06-02 00:00:00-03:00</th>\n",
       "      <th>2023-06-05 00:00:00-03:00</th>\n",
       "      <th>2023-06-06 00:00:00-03:00</th>\n",
       "      <th>2023-06-07 00:00:00-03:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USIM5.SA</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.630000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>7.460000</td>\n",
       "      <td>7.610000</td>\n",
       "      <td>7.470000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.990000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.310000</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.070000</td>\n",
       "      <td>7.020000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>7.390000</td>\n",
       "      <td>7.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULT3.SA</td>\n",
       "      <td>27.030001</td>\n",
       "      <td>27.200001</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>26.440001</td>\n",
       "      <td>26.620001</td>\n",
       "      <td>26.92</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>...</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>26.530001</td>\n",
       "      <td>26.480000</td>\n",
       "      <td>26.129999</td>\n",
       "      <td>25.990000</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>27.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBSE3.SA</td>\n",
       "      <td>33.709999</td>\n",
       "      <td>33.799999</td>\n",
       "      <td>33.970001</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>32.139999</td>\n",
       "      <td>32.150002</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>31.32</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>31.690001</td>\n",
       "      <td>30.930000</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>31.040001</td>\n",
       "      <td>30.990000</td>\n",
       "      <td>30.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBSS3.SA</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.139999</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>16.219999</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>16.40</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>16.879999</td>\n",
       "      <td>17.620001</td>\n",
       "      <td>17.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRKM5.SA</td>\n",
       "      <td>26.280001</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>25.559999</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>22.690001</td>\n",
       "      <td>22.760000</td>\n",
       "      <td>23.370001</td>\n",
       "      <td>23.42</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.040001</td>\n",
       "      <td>22.969999</td>\n",
       "      <td>22.889999</td>\n",
       "      <td>22.700001</td>\n",
       "      <td>22.459999</td>\n",
       "      <td>23.030001</td>\n",
       "      <td>23.850000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>25.450001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  2023-05-09 00:00:00-03:00  2023-05-10 00:00:00-03:00  \\\n",
       "0  USIM5.SA                   7.600000                   7.630000   \n",
       "1  MULT3.SA                  27.030001                  27.200001   \n",
       "2  BBSE3.SA                  33.709999                  33.799999   \n",
       "3  JBSS3.SA                  17.790001                  17.299999   \n",
       "4  BRKM5.SA                  26.280001                  25.790001   \n",
       "\n",
       "   2023-05-11 00:00:00-03:00  2023-05-12 00:00:00-03:00  \\\n",
       "0                   7.440000                   7.460000   \n",
       "1                  27.100000                  26.850000   \n",
       "2                  33.970001                  34.160000   \n",
       "3                  17.299999                  16.139999   \n",
       "4                  25.559999                  24.320000   \n",
       "\n",
       "   2023-05-15 00:00:00-03:00  2023-05-16 00:00:00-03:00  \\\n",
       "0                   7.610000                   7.470000   \n",
       "1                  26.920000                  26.440001   \n",
       "2                  32.139999                  32.150002   \n",
       "3                  16.170000                  16.219999   \n",
       "4                  22.690001                  22.760000   \n",
       "\n",
       "   2023-05-17 00:00:00-03:00  2023-05-18 00:00:00-03:00  \\\n",
       "0                   7.720000                       7.80   \n",
       "1                  26.620001                      26.92   \n",
       "2                  31.969999                      31.32   \n",
       "3                  16.200001                      16.40   \n",
       "4                  23.370001                      23.42   \n",
       "\n",
       "   2023-05-19 00:00:00-03:00  ...  2023-05-25 00:00:00-03:00  \\\n",
       "0                   7.990000  ...                   7.280000   \n",
       "1                  27.049999  ...                  26.790001   \n",
       "2                  30.900000  ...                  31.809999   \n",
       "3                  17.000000  ...                  16.430000   \n",
       "4                  24.180000  ...                  23.040001   \n",
       "\n",
       "   2023-05-26 00:00:00-03:00  2023-05-29 00:00:00-03:00  \\\n",
       "0                   7.310000                   7.280000   \n",
       "1                  26.920000                  26.790001   \n",
       "2                  31.900000                  32.090000   \n",
       "3                  16.400000                  16.410000   \n",
       "4                  22.969999                  22.889999   \n",
       "\n",
       "   2023-05-30 00:00:00-03:00  2023-05-31 00:00:00-03:00  \\\n",
       "0                   7.070000                   7.020000   \n",
       "1                  26.750000                  26.530001   \n",
       "2                  31.690001                  30.930000   \n",
       "3                  16.410000                  16.799999   \n",
       "4                  22.700001                  22.459999   \n",
       "\n",
       "   2023-06-01 00:00:00-03:00  2023-06-02 00:00:00-03:00  \\\n",
       "0                   7.160000                   7.380000   \n",
       "1                  26.480000                  26.129999   \n",
       "2                  30.520000                  30.990000   \n",
       "3                  16.410000                  16.770000   \n",
       "4                  23.030001                  23.850000   \n",
       "\n",
       "   2023-06-05 00:00:00-03:00  2023-06-06 00:00:00-03:00  \\\n",
       "0                   7.410000                   7.390000   \n",
       "1                  25.990000                  26.570000   \n",
       "2                  31.040001                  30.990000   \n",
       "3                  16.879999                  17.620001   \n",
       "4                  24.100000                  24.850000   \n",
       "\n",
       "   2023-06-07 00:00:00-03:00  \n",
       "0                   7.340000  \n",
       "1                  27.080000  \n",
       "2                  30.990000  \n",
       "3                  17.660000  \n",
       "4                  25.450001  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64421740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_row(df):\n",
    "    # normalizar por coluna para evitar o impacto da diferença entre as ações\n",
    "    df = df.subtract(df.min(axis=1).to_numpy(), axis=0)\n",
    "    df = df.divide(df.max(axis=1).to_numpy(), axis=0)\n",
    "    return df\n",
    "\n",
    "normalized_data = normalize_by_row(data.iloc[:, 1:])\n",
    "\n",
    "X = normalized_data.iloc[:, :-1]\n",
    "y = normalized_data.iloc[:, -1]\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "X_train, y_train = X_train.to_numpy(), y_train.to_numpy()\n",
    "X_test, y_test = X_test.to_numpy(), y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6a06ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data#.iloc[2]\n",
    "dt = data.iloc[:, 1:]\n",
    "dt = dt.subtract(dt.min(axis=1).to_numpy(), axis=0)\n",
    "dt = dt.divide(dt.max(axis=1).to_numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88254039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2023-05-09 00:00:00-03:00</th>\n",
       "      <th>2023-05-10 00:00:00-03:00</th>\n",
       "      <th>2023-05-11 00:00:00-03:00</th>\n",
       "      <th>2023-05-12 00:00:00-03:00</th>\n",
       "      <th>2023-05-15 00:00:00-03:00</th>\n",
       "      <th>2023-05-16 00:00:00-03:00</th>\n",
       "      <th>2023-05-17 00:00:00-03:00</th>\n",
       "      <th>2023-05-18 00:00:00-03:00</th>\n",
       "      <th>2023-05-19 00:00:00-03:00</th>\n",
       "      <th>2023-05-22 00:00:00-03:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-05-25 00:00:00-03:00</th>\n",
       "      <th>2023-05-26 00:00:00-03:00</th>\n",
       "      <th>2023-05-29 00:00:00-03:00</th>\n",
       "      <th>2023-05-30 00:00:00-03:00</th>\n",
       "      <th>2023-05-31 00:00:00-03:00</th>\n",
       "      <th>2023-06-01 00:00:00-03:00</th>\n",
       "      <th>2023-06-02 00:00:00-03:00</th>\n",
       "      <th>2023-06-05 00:00:00-03:00</th>\n",
       "      <th>2023-06-06 00:00:00-03:00</th>\n",
       "      <th>2023-06-07 00:00:00-03:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.608248</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268042</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>0.268042</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.329897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.371901</td>\n",
       "      <td>0.520662</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.876032</td>\n",
       "      <td>0.719008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.661157</td>\n",
       "      <td>0.628099</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>0.404958</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479338</td>\n",
       "      <td>0.900826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.876373</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.947803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445055</td>\n",
       "      <td>0.447803</td>\n",
       "      <td>0.398351</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.112637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354395</td>\n",
       "      <td>0.379121</td>\n",
       "      <td>0.431319</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.112637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>0.129121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.521212</td>\n",
       "      <td>0.606060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175758</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.448484</td>\n",
       "      <td>0.896970</td>\n",
       "      <td>0.921212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871728</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.078534</td>\n",
       "      <td>0.238220</td>\n",
       "      <td>0.251309</td>\n",
       "      <td>0.450262</td>\n",
       "      <td>0.246073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151833</td>\n",
       "      <td>0.133508</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>0.062828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149215</td>\n",
       "      <td>0.363875</td>\n",
       "      <td>0.429320</td>\n",
       "      <td>0.625655</td>\n",
       "      <td>0.782723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063106</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063106</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.325243</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.791262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674757</td>\n",
       "      <td>0.791262</td>\n",
       "      <td>0.660195</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.543690</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.684466</td>\n",
       "      <td>0.800971</td>\n",
       "      <td>0.723301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107661</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.436853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554865</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.517598</td>\n",
       "      <td>0.544514</td>\n",
       "      <td>0.774327</td>\n",
       "      <td>0.755694</td>\n",
       "      <td>0.766046</td>\n",
       "      <td>0.890269</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197473</td>\n",
       "      <td>0.394947</td>\n",
       "      <td>0.620629</td>\n",
       "      <td>0.507787</td>\n",
       "      <td>0.620629</td>\n",
       "      <td>0.564206</td>\n",
       "      <td>0.648840</td>\n",
       "      <td>0.592418</td>\n",
       "      <td>0.423158</td>\n",
       "      <td>0.253893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705260</td>\n",
       "      <td>0.564206</td>\n",
       "      <td>0.535998</td>\n",
       "      <td>0.282105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377707</td>\n",
       "      <td>0.971716</td>\n",
       "      <td>0.943429</td>\n",
       "      <td>0.943429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.254717</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273586</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.462265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462265</td>\n",
       "      <td>0.424529</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.509435</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.594339</td>\n",
       "      <td>0.867924</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.159725</td>\n",
       "      <td>0.208337</td>\n",
       "      <td>0.375007</td>\n",
       "      <td>0.381952</td>\n",
       "      <td>0.333339</td>\n",
       "      <td>0.368062</td>\n",
       "      <td>0.631957</td>\n",
       "      <td>0.520843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659735</td>\n",
       "      <td>0.659735</td>\n",
       "      <td>0.673624</td>\n",
       "      <td>0.368062</td>\n",
       "      <td>0.236116</td>\n",
       "      <td>0.423618</td>\n",
       "      <td>0.436812</td>\n",
       "      <td>0.819223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040885</td>\n",
       "      <td>0.132876</td>\n",
       "      <td>0.102212</td>\n",
       "      <td>0.275972</td>\n",
       "      <td>0.143097</td>\n",
       "      <td>0.275972</td>\n",
       "      <td>0.306637</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.408848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439512</td>\n",
       "      <td>0.419070</td>\n",
       "      <td>0.408848</td>\n",
       "      <td>0.153318</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.122655</td>\n",
       "      <td>0.140309</td>\n",
       "      <td>0.662264</td>\n",
       "      <td>0.959062</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.244755</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.237762</td>\n",
       "      <td>0.440560</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.580419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>0.251749</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.251749</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.916083</td>\n",
       "      <td>0.804195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245729</td>\n",
       "      <td>0.304862</td>\n",
       "      <td>0.767411</td>\n",
       "      <td>0.818660</td>\n",
       "      <td>0.628121</td>\n",
       "      <td>0.580815</td>\n",
       "      <td>0.637320</td>\n",
       "      <td>0.642575</td>\n",
       "      <td>0.617608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681998</td>\n",
       "      <td>0.965835</td>\n",
       "      <td>0.893561</td>\n",
       "      <td>0.837056</td>\n",
       "      <td>0.842313</td>\n",
       "      <td>0.809461</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132598</td>\n",
       "      <td>0.337017</td>\n",
       "      <td>0.546962</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>0.453039</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.834254</td>\n",
       "      <td>0.795580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646408</td>\n",
       "      <td>0.607735</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.082874</td>\n",
       "      <td>0.198895</td>\n",
       "      <td>0.182320</td>\n",
       "      <td>0.685083</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.666668</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.712122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.409092</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.409092</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106062</td>\n",
       "      <td>0.272728</td>\n",
       "      <td>0.272728</td>\n",
       "      <td>0.727274</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.149159</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.331933</td>\n",
       "      <td>0.359243</td>\n",
       "      <td>0.388656</td>\n",
       "      <td>0.296218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443277</td>\n",
       "      <td>0.546219</td>\n",
       "      <td>0.506302</td>\n",
       "      <td>0.447479</td>\n",
       "      <td>0.371848</td>\n",
       "      <td>0.550420</td>\n",
       "      <td>0.626050</td>\n",
       "      <td>0.665966</td>\n",
       "      <td>0.796218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171462</td>\n",
       "      <td>0.443967</td>\n",
       "      <td>0.391916</td>\n",
       "      <td>0.456213</td>\n",
       "      <td>0.064297</td>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.076546</td>\n",
       "      <td>0.333740</td>\n",
       "      <td>0.156153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523575</td>\n",
       "      <td>0.443967</td>\n",
       "      <td>0.419471</td>\n",
       "      <td>0.535822</td>\n",
       "      <td>0.511327</td>\n",
       "      <td>0.548070</td>\n",
       "      <td>0.751417</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    2023-05-09 00:00:00-03:00  2023-05-10 00:00:00-03:00  \\\n",
       "0                    0.597938                   0.628866   \n",
       "1                    0.859504                   1.000000   \n",
       "2                    0.876373                   0.901099   \n",
       "3                    1.000000                   0.703030   \n",
       "4                    1.000000                   0.871728   \n",
       "5                    0.063106                   0.058253   \n",
       "6                    0.140787                   0.140787   \n",
       "7                    0.197473                   0.394947   \n",
       "8                    0.603774                   0.490566   \n",
       "9                    0.000000                   0.020833   \n",
       "10                   0.000000                   0.040885   \n",
       "11                   0.118881                   0.000000   \n",
       "12                   0.000000                   0.245729   \n",
       "13                   0.000000                   0.132598   \n",
       "14                   0.424242                   0.666668   \n",
       "15                   0.000000                   0.010504   \n",
       "16                   0.000000                   0.171462   \n",
       "\n",
       "    2023-05-11 00:00:00-03:00  2023-05-12 00:00:00-03:00  \\\n",
       "0                    0.432990                   0.453608   \n",
       "1                    0.917355                   0.710744   \n",
       "2                    0.947803                   1.000000   \n",
       "3                    0.703030                   0.000000   \n",
       "4                    0.811518                   0.486911   \n",
       "5                    0.000000                   0.063106   \n",
       "6                    0.020704                   0.000000   \n",
       "7                    0.620629                   0.507787   \n",
       "8                    0.396226                   0.254717   \n",
       "9                    0.159725                   0.208337   \n",
       "10                   0.132876                   0.102212   \n",
       "11                   0.447552                   0.244755   \n",
       "12                   0.304862                   0.767411   \n",
       "13                   0.337017                   0.546962   \n",
       "14                   0.939394                   0.712122   \n",
       "15                   0.149159                   0.357143   \n",
       "16                   0.443967                   0.391916   \n",
       "\n",
       "    2023-05-15 00:00:00-03:00  2023-05-16 00:00:00-03:00  \\\n",
       "0                    0.608248                   0.463917   \n",
       "1                    0.768595                   0.371901   \n",
       "2                    0.445055                   0.447803   \n",
       "3                    0.018182                   0.048485   \n",
       "4                    0.060210                   0.078534   \n",
       "5                    0.504854                   0.325243   \n",
       "6                    0.107661                   0.033126   \n",
       "7                    0.620629                   0.564206   \n",
       "8                    0.396226                   0.000000   \n",
       "9                    0.375007                   0.381952   \n",
       "10                   0.275972                   0.143097   \n",
       "11                   0.279720                   0.237762   \n",
       "12                   0.818660                   0.628121   \n",
       "13                   0.640883                   0.508287   \n",
       "14                   1.000000                   0.742424   \n",
       "15                   0.235294                   0.369748   \n",
       "16                   0.456213                   0.064297   \n",
       "\n",
       "    2023-05-17 00:00:00-03:00  2023-05-18 00:00:00-03:00  \\\n",
       "0                    0.721649                   0.804124   \n",
       "1                    0.520662                   0.768595   \n",
       "2                    0.398351                   0.219780   \n",
       "3                    0.036364                   0.157576   \n",
       "4                    0.238220                   0.251309   \n",
       "5                    0.441748                   0.791262   \n",
       "6                    0.372671                   0.420290   \n",
       "7                    0.648840                   0.592418   \n",
       "8                    0.273586                   0.528302   \n",
       "9                    0.333339                   0.368062   \n",
       "10                   0.275972                   0.306637   \n",
       "11                   0.440560                   0.734266   \n",
       "12                   0.580815                   0.637320   \n",
       "13                   0.453039                   0.574586   \n",
       "14                   0.378788                   0.409092   \n",
       "15                   0.331933                   0.359243   \n",
       "16                   0.085731                   0.076546   \n",
       "\n",
       "    2023-05-19 00:00:00-03:00  2023-05-22 00:00:00-03:00  ...  \\\n",
       "0                    1.000000                   0.845361  ...   \n",
       "1                    0.876032                   0.719008  ...   \n",
       "2                    0.104395                   0.112637  ...   \n",
       "3                    0.521212                   0.606060  ...   \n",
       "4                    0.450262                   0.246073  ...   \n",
       "5                    1.000000                   0.956311  ...   \n",
       "6                    0.536232                   0.436853  ...   \n",
       "7                    0.423158                   0.253893  ...   \n",
       "8                    0.622642                   0.462265  ...   \n",
       "9                    0.631957                   0.520843  ...   \n",
       "10                   0.470176                   0.408848  ...   \n",
       "11                   0.664336                   0.580419  ...   \n",
       "12                   0.642575                   0.617608  ...   \n",
       "13                   0.834254                   0.795580  ...   \n",
       "14                   0.636364                   0.545456  ...   \n",
       "15                   0.388656                   0.296218  ...   \n",
       "16                   0.333740                   0.156153  ...   \n",
       "\n",
       "    2023-05-25 00:00:00-03:00  2023-05-26 00:00:00-03:00  \\\n",
       "0                    0.268042                   0.298969   \n",
       "1                    0.661157                   0.768595   \n",
       "2                    0.354395                   0.379121   \n",
       "3                    0.175758                   0.157576   \n",
       "4                    0.151833                   0.133508   \n",
       "5                    0.674757                   0.791262   \n",
       "6                    0.554865                   0.666667   \n",
       "7                    0.705260                   0.564206   \n",
       "8                    0.462265                   0.424529   \n",
       "9                    0.659735                   0.659735   \n",
       "10                   0.439512                   0.419070   \n",
       "11                   0.363637                   0.174825   \n",
       "12                   0.681998                   0.965835   \n",
       "13                   0.646408                   0.607735   \n",
       "14                   0.515152                   0.500000   \n",
       "15                   0.443277                   0.546219   \n",
       "16                   0.523575                   0.443967   \n",
       "\n",
       "    2023-05-29 00:00:00-03:00  2023-05-30 00:00:00-03:00  \\\n",
       "0                    0.268042                   0.051547   \n",
       "1                    0.661157                   0.628099   \n",
       "2                    0.431319                   0.321429   \n",
       "3                    0.163636                   0.163636   \n",
       "4                    0.112565                   0.062828   \n",
       "5                    0.660195                   0.669903   \n",
       "6                    0.594203                   0.517598   \n",
       "7                    0.535998                   0.282105   \n",
       "8                    0.330189                   0.509435   \n",
       "9                    0.673624                   0.368062   \n",
       "10                   0.408848                   0.153318   \n",
       "11                   0.251749                   0.279720   \n",
       "12                   0.893561                   0.837056   \n",
       "13                   0.243094                   0.165746   \n",
       "14                   0.409092                   0.318182   \n",
       "15                   0.506302                   0.447479   \n",
       "16                   0.419471                   0.535822   \n",
       "\n",
       "    2023-05-31 00:00:00-03:00  2023-06-01 00:00:00-03:00  \\\n",
       "0                    0.000000                   0.144330   \n",
       "1                    0.446281                   0.404958   \n",
       "2                    0.112637                   0.000000   \n",
       "3                    0.400000                   0.163636   \n",
       "4                    0.000000                   0.149215   \n",
       "5                    0.543690                   0.441748   \n",
       "6                    0.544514                   0.774327   \n",
       "7                    0.000000                   0.377707   \n",
       "8                    0.320755                   0.594339   \n",
       "9                    0.236116                   0.423618   \n",
       "10                   0.010222                   0.122655   \n",
       "11                   0.251749                   0.755245   \n",
       "12                   0.842313                   0.809461   \n",
       "13                   0.193370                   0.082874   \n",
       "14                   0.000000                   0.106062   \n",
       "15                   0.371848                   0.550420   \n",
       "16                   0.511327                   0.548070   \n",
       "\n",
       "    2023-06-02 00:00:00-03:00  2023-06-05 00:00:00-03:00  \\\n",
       "0                    0.371134                   0.402062   \n",
       "1                    0.115702                   0.000000   \n",
       "2                    0.129121                   0.142857   \n",
       "3                    0.381818                   0.448484   \n",
       "4                    0.363875                   0.429320   \n",
       "5                    0.635922                   0.684466   \n",
       "6                    0.755694                   0.766046   \n",
       "7                    0.971716                   0.943429   \n",
       "8                    0.867924                   0.839623   \n",
       "9                    0.436812                   0.819223   \n",
       "10                   0.140309                   0.662264   \n",
       "11                   1.000000                   0.993007   \n",
       "12                   0.915900                   0.801577   \n",
       "13                   0.198895                   0.182320   \n",
       "14                   0.272728                   0.272728   \n",
       "15                   0.626050                   0.665966   \n",
       "16                   0.751417                   0.838421   \n",
       "\n",
       "    2023-06-06 00:00:00-03:00  2023-06-07 00:00:00-03:00  \n",
       "0                    0.381443                   0.329897  \n",
       "1                    0.479338                   0.900826  \n",
       "2                    0.129121                   0.129121  \n",
       "3                    0.896970                   0.921212  \n",
       "4                    0.625655                   0.782723  \n",
       "5                    0.800971                   0.723301  \n",
       "6                    0.890269                   1.000000  \n",
       "7                    0.943429                   1.000000  \n",
       "8                    1.000000                   0.783019  \n",
       "9                    1.000000                   0.993047  \n",
       "10                   0.959062                   1.000000  \n",
       "11                   0.916083                   0.804195  \n",
       "12                   1.000000                   0.942182  \n",
       "13                   0.685083                   1.000000  \n",
       "14                   0.727274                   0.757576  \n",
       "15                   0.796218                   1.000000  \n",
       "16                   1.000000                   0.993785  \n",
       "\n",
       "[17 rows x 22 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ccbd336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 09:59:26.318531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-11 09:59:26.320095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-11 09:59:26.321011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-11 09:59:26.493341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-11 09:59:26.494440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-11 09:59:26.495369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-11 09:59:26.822811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-11 09:59:26.825361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-11 09:59:26.826446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 6ms/step - loss: 0.4223\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0983\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0677\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0711\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0601\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0716\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0752\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0667\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0664\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0529\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0520\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0536\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0508\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0535\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0519\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0507\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0542\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0497\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0549\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0519\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0460\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0453\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0438\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0443\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0478\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0380\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0399\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0427\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0297\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0376\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0346\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0224\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0214\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0191\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0251\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0228\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0215\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0121\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0135\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0108\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0120\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0122\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0035\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0265\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0079\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0090\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "Predições:\n",
      "Entrada: [0.         0.02083343 0.15972495 0.20833695 0.37500705 0.38195152\n",
      " 0.33333886 0.36806191 0.63195666 0.52084304 0.61112124 0.27083857\n",
      " 0.65973457 0.65973457 0.67362352 0.36806191 0.23611552 0.42361838\n",
      " 0.43681176 0.81922346 1.        ]\n",
      "Valor real: 0.993046903232865\n",
      "Predição: 1.1517012\n",
      "\n",
      "Entrada: [0.42424212 0.66666763 0.93939398 0.71212178 1.         0.74242407\n",
      " 0.37878797 0.4090917  0.6363639  0.5454556  0.45454585 0.45454585\n",
      " 0.51515187 0.5        0.4090917  0.31818195 0.         0.10606161\n",
      " 0.2727278  0.2727278  0.72727365]\n",
      "Valor real: 0.7575759327225963\n",
      "Predição: 0.89468133\n",
      "\n",
      "Entrada: [0.5979382  0.62886625 0.43298986 0.4536084  0.60824771 0.46391743\n",
      " 0.72164944 0.8041241  1.         0.84536118 0.48453597 0.38144326\n",
      " 0.26804153 0.2989691  0.26804153 0.0515466  0.         0.14432979\n",
      " 0.37113424 0.4020618  0.38144326]\n",
      "Valor real: 0.3298971555428399\n",
      "Predição: 0.68713903\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 09:59:36.092672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-11 09:59:36.094085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-11 09:59:36.094965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape dos dados de treinamento para o formato esperado pela RNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Construção do modelo\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1)\n",
    "\n",
    "# Reshape dos dados de teste para o formato esperado pela RNN\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Predição dos dados de teste\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Predições:\")\n",
    "for i in range(len(predictions)):\n",
    "    print(\"Entrada:\", X_test[i].flatten())\n",
    "    print(\"Valor real:\", y_test[i])\n",
    "    print(\"Predição:\", predictions[i][0])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
